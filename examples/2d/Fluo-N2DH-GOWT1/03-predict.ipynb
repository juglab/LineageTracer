{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fcd8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, json\n",
    "from LineageTracer.utils.create_dicts import create_test_configs_dict\n",
    "from LineageTracer.test import output_embeddings, compute_tracklets, stitch_tracklets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885046e1",
   "metadata": {},
   "source": [
    "### Specify the path to the evaluation images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae0ba3",
   "metadata": {},
   "source": [
    "Here, we specify the path to the generated crops obtained from the test images, in `crops_dir`.<br>\n",
    "We also specify the path to the actual label masks, using `data_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f269e5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation test image crops shall be read from: ../../../data/Fluo-N2DH-GOWT1\n"
     ]
    }
   ],
   "source": [
    "crops_dir = 'crops'\n",
    "data_dir = '../../../data'\n",
    "project_name = 'Fluo-N2DH-GOWT1'\n",
    "print(\"Evaluation test image crops shall be read from: {}\".format(os.path.join(data_dir, project_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d43fff",
   "metadata": {},
   "source": [
    "Specify path to `data_properties.json` which was generated in the first notebook `01-data.ipynb`. <br>\n",
    "Also, specify the path to the model trained by you. <br>\n",
    "Notice, that we use `object_size` equal to `int(data['mean_object_size']` during inference, and not `int(data['min_object_size'])`. We notice that this empirically gives better results!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eacf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment for the model trained by you\n",
    "checkpoint_path = os.path.join('experiment', project_name+'-'+'demo', 'best_model.pth')\n",
    "if os.path.isfile('data_properties.json'): \n",
    "    with open('data_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        object_size = int(data['mean_object_size'])\n",
    "        num_tracklets = int(data['mean_num_tracklets'])\n",
    "        mean_tracklet_length = int(data['mean_length_tracklet'])\n",
    "        min_tracklet_length = int(data['min_length_tracklet'])\n",
    "        std_object_size= np.maximum(data['std_object_size_x'], data['std_object_size_y'])\n",
    "if os.path.isfile('train_properties.json'): \n",
    "    with open('train_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        num_offset_channels = int(data['num_offset_channels'])\n",
    "        num_intensity_channels = int(data['num_intensity_channels'])\n",
    "        num_latent_channels = int(data['num_latent_channels'])\n",
    "        num_output_channels = int(data['num_output_channels'])\n",
    "        margin = float(data['margin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ee4777",
   "metadata": {},
   "source": [
    "Specify, where the output should be saved using variable `save_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f965761",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a58067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model weights found at : experiment/Fluo-N2DH-GOWT1-demo/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Trained model weights found at : {}\".format(checkpoint_path))\n",
    "else:\n",
    "    print(\"Trained model weights were not found at the specified location!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce8b26",
   "metadata": {},
   "source": [
    "### Create `test_configs` dictionary from the above-specified parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46746c3c",
   "metadata": {},
   "source": [
    "Set `save_results` to `False` if one does not have the ground truth tracking on the test movie for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eabfaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`test_configs` dictionary successfully created with: \n",
      " -- evaluation images accessed from ../../../data, \n",
      " -- trained weights accessed from experiment/Fluo-N2DH-GOWT1-demo/best_model.pth, \n",
      " -- output directory chosen as ./inference\n"
     ]
    }
   ],
   "source": [
    "test_configs = create_test_configs_dict(crops_dir = crops_dir,\n",
    "                                        data_dir = data_dir,\n",
    "                                        project_name = project_name,\n",
    "                                        checkpoint_path = checkpoint_path,\n",
    "                                        num_fg_points = object_size,\n",
    "                                        std_object_size = std_object_size,\n",
    "                                        num_sampled_tracklets = num_tracklets,\n",
    "                                        mean_tracklet_length = mean_tracklet_length, \n",
    "                                        min_tracklet_length = min_tracklet_length,\n",
    "                                        save_dir = save_dir,\n",
    "                                        save_results = True,\n",
    "                                        num_offset_channels = num_offset_channels,\n",
    "                                        num_intensity_channels =num_intensity_channels,\n",
    "                                        num_latent_channels = num_latent_channels, \n",
    "                                        num_output_channels = num_output_channels,\n",
    "                                        margin = margin\n",
    "                                        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685258db",
   "metadata": {},
   "source": [
    "### Generate embeddings from instance crops in test images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f80b5",
   "metadata": {},
   "source": [
    "In the next cell, each mask crop from the test images is fed to the trained model. <br>\n",
    "The corresponding embedding is saved with the name `t_id.npy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b2cab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`test` dataloader created! Accessing data from crops/test/\n",
      "Number of tracklets in `test` directory is 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 92/92 [00:12<00:00,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "output_embeddings(test_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96383cae",
   "metadata": {},
   "source": [
    "### Generate tracklets from embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e795a9d",
   "metadata": {},
   "source": [
    "In this step, we identify small tracklets where the learning criteria, going forward in time, is satisfied i.e. distance of an anchor at the time point $t$ to the distance of a positive sample at time point $t+1$, + the margin distance is less than distance of an anchor at time point $t$ to the distance of a negative sample at the time point $t+1$. <br>\n",
    "After the execution of this step, if `save_results` was set to `True`, we report the `TRA` metric (between $0$ and $1$) which compares our predicted tracking to the ground truth tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9018c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 91/91 [01:23<00:00,  1.09it/s]\n",
      "100%|███████████████████████████████████████| 2572/2572 [00:36<00:00, 69.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRA measure: 0.968592\n"
     ]
    }
   ],
   "source": [
    "avg_distance, std_distance= compute_tracklets(test_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffe14b",
   "metadata": {},
   "source": [
    "### (Optional) Generate Lineage Tree from tracklets by solving an Integer Linear Program (ILP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabada89",
   "metadata": {},
   "source": [
    "In this step, we stitch tracklets produced by `compute_tracklets` function to form a lineage tree. <br>\n",
    "For this purpose, we create a directed graph. Here, each tracklet is considered as one node. Edges are built between nodes (tracklets) which are contiguous in time. <br> \n",
    "This is an optional step and would lead to a slight increase in the `TRA` metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dcaba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 64/64 [00:00<00:00, 71127.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-01-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 64/64 [00:00<00:00, 29086.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "Optimize a model with 192 rows, 76 columns and 117 nonzeros\n",
      "Model fingerprint: 0x5585e63f\n",
      "Variable types: 0 continuous, 76 integer (76 binary)\n",
      "Coefficient statistics:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matrix range     [1e+00, 2e+00]\n",
      "  Objective range  [2e-03, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+00]\n",
      "Found heuristic solution: objective 124.0045841\n",
      "Presolve removed 192 rows and 76 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.04 seconds (0.00 work units)\n",
      "Thread count was 1 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 122.006 124.005 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.220062618947e+02, best bound 1.220062618947e+02, gap 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 64/64 [00:00<00:00, 61230.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime is 0.06509709358215332\n",
      "Saving result to text file ...\n",
      "Create res_track.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 64/64 [00:47<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRA measure: 0.969008\n"
     ]
    }
   ],
   "source": [
    "stitch_tracklets(test_configs, max_dist_embedding = avg_distance+5*std_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5010edd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
