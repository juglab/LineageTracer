{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548ad10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "from scipy.special import perm\n",
    "import numpy as np\n",
    "from LineageTracer.utils.create_dicts import create_dataset_dict, create_model_dict, create_loss_dict, create_configs\n",
    "from LineageTracer.train import begin_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7079ec06",
   "metadata": {},
   "source": [
    "### Specify the path to train, val crops which we would like to train the network for:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106ce43",
   "metadata": {},
   "source": [
    "The train-val images, masks will be accessed from the path specified by `data_dir` and `project-name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc328aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Name chosen as : Fluo-C3DL-MDA231. \n",
      "Train-Val images-masks crops will be accessed from : dicts\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'dicts'\n",
    "project_name = 'Fluo-C3DL-MDA231'\n",
    "\n",
    "print(\"Project Name chosen as : {}. \\nTrain-Val images-masks crops will be accessed from : {}\".format(project_name, data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0083a1cb",
   "metadata": {},
   "source": [
    "### Obtain properties of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f1b760",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here, we read the dataset.json file prepared in the 01-data notebook previously.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f19f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('data_properties.json'): \n",
    "    with open('data_properties.json') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        object_size = int(data['min_object_size'])\n",
    "        num_tracklets = int(data['mean_num_tracklets'])\n",
    "        tracklet_length = int(data['mean_length_tracklet'])\n",
    "        std_object_size= np.max(np.array([data['std_object_size_x'], data['std_object_size_y'], data['std_object_size_z']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70838f6",
   "metadata": {},
   "source": [
    "### Specify training dataset-related parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789eaa8",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "\n",
    "* The `train_size` attribute indicates the number of triplets which the network would see in one complete epoch. \n",
    "Here, the triplets would include one anchor, one positive sample taken from the same tracklet as the anchor and one negative sample. \n",
    "\n",
    "Although the `train_size` can be explicitly specified, we use a heuristic to assess a rough measure of how many triplets would exist.\n",
    "\n",
    "In the cell after this one, a `train_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da55e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(perm(len(os.listdir(os.path.join(data_dir, 'train'))), 2)/num_tracklets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da76ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train_dataset_dict` dictionary successfully created with: \n",
      " -- train images accessed from dicts/Fluo-C3DL-MDA231/train/images, \n",
      " -- number of images per epoch equal to 36, \n",
      " -- batch size set at 1, \n"
     ]
    }
   ],
   "source": [
    "train_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                         project_name = project_name,  \n",
    "                                         size = train_size, \n",
    "                                         num_sampled_tracklets = num_tracklets,\n",
    "                                         num_fg_points = object_size,\n",
    "                                         std_object_size = std_object_size,\n",
    "                                         type = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d71fab",
   "metadata": {},
   "source": [
    "### Specify validation dataset-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c0c39",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "\n",
    "* The `val_size` attribute indicates the number of triplets which the network would see in one complete epoch. \n",
    "Here, the triplets would include one anchor, one positive sample taken from the same tracklet as the anchor and one negative sample. \n",
    "\n",
    "Although the `val_size` can be explicitly specified, we use a heuristic to assess a rough measure of how many triplets would exist.\n",
    "\n",
    "In the cell after this one, a `val_dataset_dict` dictionary is generated from the parameters specified here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "918cf7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(perm(len(os.listdir(os.path.join(data_dir, 'val'))), 2)/num_tracklets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7969131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`val_dataset_dict` dictionary successfully created with: \n",
      " -- val images accessed from dicts/Fluo-C3DL-MDA231/val/images, \n",
      " -- number of images per epoch equal to 32, \n",
      " -- batch size set at 1, \n"
     ]
    }
   ],
   "source": [
    "val_dataset_dict = create_dataset_dict(data_dir = data_dir, \n",
    "                                         project_name = project_name,  \n",
    "                                         size = val_size, \n",
    "                                         num_sampled_tracklets = num_tracklets,\n",
    "                                         num_fg_points = object_size,\n",
    "                                         std_object_size = std_object_size,\n",
    "                                         type = 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60622909",
   "metadata": {},
   "source": [
    "### Specify model-related parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37f65d",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "\n",
    "* Set the `num_latent_channels` attribute equal to the dimensionality of the latent embedding. Set this to `zero`. in case you are not using latent embeddings\n",
    "\n",
    "In the cell after this one, a `model_dataset_dict` dictionary is generated from the parameters specified here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81a67039",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_offset_channels = 3\n",
    "num_intensity_channels = 1\n",
    "num_latent_channels = 0\n",
    "num_output_channels = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443cdba",
   "metadata": {},
   "source": [
    "### Create the `model_dict` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b29044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`model_dict` dictionary successfully created with: \n",
      " -- number of offset channels equal to 3, \n",
      " -- number of intensity channels equal to 1, \n",
      " -- number of latent channels equal to 0, \n",
      " -- number of output channels equal to 32\n"
     ]
    }
   ],
   "source": [
    "model_dict = create_model_dict(num_fg_points = object_size, \n",
    "                               num_offset_channels = num_offset_channels, \n",
    "                               num_latent_channels = num_latent_channels,\n",
    "                               num_output_channels = num_output_channels\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bc5c4a",
   "metadata": {},
   "source": [
    "### Create the `loss_dict` dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17973997",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e894259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`loss_dict` dictionary successfully created with: \n",
      " -- margin equal to 0.200\n"
     ]
    }
   ],
   "source": [
    "loss_dict = create_loss_dict(margin=margin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2487c8e4",
   "metadata": {},
   "source": [
    "### Create the `configs` dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d533570",
   "metadata": {},
   "source": [
    "Some hints:\n",
    "\n",
    "* The `n_epochs` attribute determines how long the training should proceed.\n",
    "* The `save_dir` attribute identifies the location where the checkpoints and loss curve details are saved. If one wishes to resume training from a previous checkpoint, they could point resume_path attribute appropriately. For example, one could set `resume_path = './experiment/Fluo-C3DL-MDA231-demo/checkpoint.pth'` to resume training from the last checkpoint.\n",
    "\n",
    "In the cell after this one, a `configs` dictionary is generated from the parameters specified here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b90d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "save_dir = os.path.join('experiment', project_name+'-'+'demo')\n",
    "resume_path  = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf06a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`configs` dictionary successfully created with: \n",
      " -- n_epochs equal to 20, \n",
      " -- save_dir equal to experiment/Fluo-C3DL-MDA231-demo, \n"
     ]
    }
   ],
   "source": [
    "configs = create_configs(n_epochs = n_epochs,\n",
    "                         resume_path = resume_path, \n",
    "                         save_dir = save_dir, \n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8b66e",
   "metadata": {},
   "source": [
    "Save the properties of the model in a `json` file. This will be accessed later during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639c1e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train config properties of the `Fluo-C3DL-MDA231` dataset is saved to `train_properties.json`\n"
     ]
    }
   ],
   "source": [
    "train_properties_dir = {}\n",
    "train_properties_dir['num_offset_channels']=num_offset_channels\n",
    "train_properties_dir['num_intensity_channels']=num_intensity_channels\n",
    "train_properties_dir['num_latent_channels'] =num_latent_channels\n",
    "train_properties_dir['num_output_channels'] =num_output_channels\n",
    "train_properties_dir['margin']= margin\n",
    "                             \n",
    "with open('train_properties.json', 'w') as outfile:\n",
    "    json.dump(train_properties_dir, outfile)\n",
    "    print(\"Train config properties of the `{}` dataset is saved to `train_properties.json`\".format(project_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d9385",
   "metadata": {},
   "source": [
    "### Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "109df540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`train` dataloader created! Accessing data from dicts/train/\n",
      "Number of tracklets in `train` directory is 33\n",
      "`val` dataloader created! Accessing data from dicts/val/\n",
      "Number of tracklets in `val` directory is 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created  loss function with: margin: 0.2\n",
      "*************************\n",
      "Created logger with keys:  ('train', 'val')\n",
      "Starting epoch 0\n",
      "learning rate: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manan/Projects/LineageTracer/LineageTracer/criterions/lineage_tracer_loss.py:29: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484772347/work/torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
      "  embeddings.t())  # stands for add matrix multiplication in place -2*dist + embeddings*embeddings_tranposed\n",
      "100%|███████████████████████████████████████████| 36/36 [00:12<00:00,  2.85it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.076\n",
      "===> val loss: 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 1\n",
      "learning rate: 0.0004977494364660346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.21it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.006\n",
      "===> val loss: 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 2\n",
      "learning rate: 0.0004954977417064171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.19it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.001\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 3\n",
      "learning rate: 0.0004932449094349202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.001\n",
      "===> val loss: 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 4\n",
      "learning rate: 0.0004909909332982877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.17it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.001\n",
      "===> val loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 5\n",
      "learning rate: 0.0004887358068751748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 6\n",
      "learning rate: 0.0004864795236750653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.25it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 7\n",
      "learning rate: 0.00048422207713716544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.16it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 8\n",
      "learning rate: 0.00048196346062927547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.12it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 9\n",
      "learning rate: 0.00047970366744663594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.26it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 10\n",
      "learning rate: 0.00047744269081074987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 11\n",
      "learning rate: 0.0004751805238681794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.07it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 12\n",
      "learning rate: 0.000472917159689316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 13\n",
      "learning rate: 0.00047065259126712457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.23it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 14\n",
      "learning rate: 0.00046838681151585874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.16it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 15\n",
      "learning rate: 0.0004661198132697498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.18it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 16\n",
      "learning rate: 0.0004638515892816641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.02it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 17\n",
      "learning rate: 0.00046158213222173284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:12<00:00,  2.97it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 18\n",
      "learning rate: 0.0004593114346759497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.11it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving checkpoint\n",
      "Starting epoch 19\n",
      "learning rate: 0.00045703948914473726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 36/36 [00:11<00:00,  3.21it/s]\n",
      "100%|███████████████████████████████████████████| 32/32 [00:03<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> train loss: 0.000\n",
      "===> val loss: 0.004\n",
      "=> saving checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "begin_training(train_dataset_dict, val_dataset_dict, model_dict, loss_dict, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00889eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
