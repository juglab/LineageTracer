{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6122e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from LineageTracer.utils.preprocess_data import extract_data, reid_masks, split_train_val, pickle_data, get_data_properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdf049",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bb7737",
   "metadata": {},
   "source": [
    "Images, corresponding instance segmentations and tracking annotations (all of type `*.tif`) should be respectively present in sub-directories `images`, `masks` and `tracking-annotations`, which are located within directories `train` and `test`, which can be present at any location on your workstation, pointed to by the variable `data_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ac032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data'\n",
    "project_name = 'Fluo-C3DL-MDA231'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacc19d5",
   "metadata": {},
   "source": [
    "For the `Fluo-N2DH-GOWT1` dataset, we firstly download the data from an external url in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a641d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_data(\n",
    "    zip_url = 'https://github.com/juglab/LineageTracer/releases/download/v0.1.0/Fluo-C3DL-MDA231.zip',\n",
    "    data_dir = data_dir,\n",
    "    project_name = project_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba49e7b",
   "metadata": {},
   "source": [
    "### Re-assign Ids on Instance Segmentation Predictions for Training Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93573e4d",
   "metadata": {},
   "source": [
    "Since the instance segmentations are generated by inputting the frames of a time-lapse movie one-by-one into a trained instance segmentation model, the labels (or ids) generated for objects are arbitrarily set across time. We use the available ground truth tracking annotations to **re-identify** the labels of the segmentation to be *consistent* (so that the same object observed across time is assigned **the same id**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e4dbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory : ../../../data/Fluo-C3DL-MDA231/download/train/masks-reid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [05:08<00:00, 25.71s/it]\n"
     ]
    }
   ],
   "source": [
    "reid_masks(data_dir, os.path.join(project_name,'download/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a589b",
   "metadata": {},
   "source": [
    "### Extract some typical data properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efcf628",
   "metadata": {},
   "source": [
    "In the next cell, we extract properties such as average object size in the dataset. This enables us to know how many pixels (voxels) to sample per object instance during the training phase in the next notebook. <br>\n",
    "These properties are saved in a file named `data_properties.json` which shall be read in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c57220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:13<00:00,  1.16s/it]\n",
      "  8%|███▋                                        | 1/12 [00:00<00:02,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum object size of the `Fluo-C3DL-MDA231/download/` dataset is equal to 85\n",
      "Mean object size of the `Fluo-C3DL-MDA231/download/` dataset is equal to 1690.1931818181818\n",
      "Maximum object size of the `Fluo-C3DL-MDA231/download/` dataset is equal to 5543\n",
      "Average object size of the `Fluo-C3DL-MDA231/download/` dataset along `x` is equal to 31.710\n",
      "Average object size of the `Fluo-C3DL-MDA231/download/` dataset along `y` is equal to 30.872\n",
      "Average object size of the `Fluo-C3DL-MDA231/download/` dataset along `z` is equal to 4.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  4.94it/s]\n",
      "  0%|                                                    | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 28\n",
      "Minimum number of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 29.333333333333332\n",
      "Maximum number of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 31\n",
      "../../../data/Fluo-C3DL-MDA231/download/train/masks-reid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:02<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of tracklet in the `Fluo-C3DL-MDA231/download/` dataset is equal to 0\n",
      "Mean number of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 9.666666666666666\n",
      "Maximum number of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 11\n",
      "Std. dev. of tracklets in the `Fluo-C3DL-MDA231/download/` dataset is equal to 2.7376905403915717\n",
      "Dataset properties of the `Fluo-C3DL-MDA231` dataset is saved to `data_properties.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_properties_dir= get_data_properties(data_dir=data_dir, project_name=os.path.join(project_name,'download/'), \n",
    "                                         train_val_name = ['train'], mode='3d')\n",
    "with open('data_properties.json', 'w') as outfile:\n",
    "    json.dump(data_properties_dir, outfile)\n",
    "    print(\"Dataset properties of the `{}` dataset is saved to `data_properties.json`\".format(project_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08504724",
   "metadata": {},
   "source": [
    "### Split image and mask frames into `train` and `val` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851e52c6",
   "metadata": {},
   "source": [
    "In order to train a tracker model, we reserve a small fraction (`subset` is set to $0.15$ by default)) of the training time frames for validation. We randomly pick consecutive, validation frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97585945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Val-Test Images/Masks copied to ../../../data/Fluo-C3DL-MDA231\n"
     ]
    }
   ],
   "source": [
    "split_train_val(data_dir, project_name, train_val_name='train', subset=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940dc3f3",
   "metadata": {},
   "source": [
    "### Re-save Instance Segmentations as *`.pkl` object files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f728ad4",
   "metadata": {},
   "source": [
    "The next cell extracts the crops from the masks and saves them in the `crops` directory (next to these notebooks). Then, all crops which have the same id are re-saved as a dictionary in the `dicts` directory. <br> Here, each file in the `dicts` directory corresponds to a certain `id` (the name of the file indicates that `id`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73792215",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:12<00:00,  1.22s/it]\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 197.58it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:02<00:00,  1.28s/it]\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 204.81it/s]\n",
      "100%|███████████████████████████████████████████| 12/12 [00:22<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "pickle_data(data_dir, project_name, train_val_names=['train', 'val', 'test'], mode='3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f4936",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
